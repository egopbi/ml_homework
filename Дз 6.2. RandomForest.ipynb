{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 6.2. Случайный лес\n",
        "\n",
        "Ваша задача - написать класс `random_forest` для решения задачи классификации на основе датасета Ирисов Фишера (`sklearn.datasets.load_iris`), принимающий на вход конструктора аргументы `n_estimators`, `max_depth`, `subspaces_dim` и `random_state`. описание этих аргументов приведено ниже. У этого класса должны быть определены методы `.fit()` и `.predict()`, а также поле `._estimators`, в котором должен храниться список алгоритмов, используемых в ансамбле.\n",
        "\n",
        "Для создания обучающей подвыборки для каждого из базовых классификаторов, Вы можете воспользоваться классом `sample`, который Вы реализовали в прошлом задании. В случае его использования, не забудьте включить его описание в файл с Вашим решением текущего задания. Мы также предлагаем вам организовать выбор подпространств для каждого дерева посредством заполнения списка `subspace_idx`, в котором будут логироваться выбранные для каждого базового классификатора подпространства.\n",
        "\n",
        "Замечание: в рамках выполнения данного задания запрещено использовать класс `sklearn.ensemble.RandomForestClassifier`. Такой код не пройдёт проверку.\n",
        "\n",
        "Подберите также гиперпараметры, на которых ваш алгоритм получает наилучшее качество (с точки зрения метрики accuracy, доли правильных ответов) на тестовой выборке с параметром `test_size`=0.3, задайте их в виде глобальных переменных N_ESTIMATORS, MAX_DEPTH, SUBSPACE_DIM.\n",
        "\n",
        "Шаблон класса:"
      ],
      "metadata": {
        "id": "upU8iWtojlkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "\n",
        "class sample(object):\n",
        "    def init(self, X, n_subspace):\n",
        "        self.idx_subspace = self.random_subspace(X, n_subspace)\n",
        "\n",
        "    def call(self, X, y):\n",
        "        idx_obj = self.bootstrap_sample(X)\n",
        "        X_sampled, y_sampled = self.get_subsample(X, y, self.idx_subspace, idx_obj)\n",
        "        return X_sampled, y_sampled\n",
        "\n",
        "    @staticmethod\n",
        "    def bootstrap_sample(X, random_state=42):\n",
        "        return np.array(np.unique(np.random.choice(len(X), len(X)))) # len(X) - это число строк- объектов в массиве X\n",
        "    @staticmethod\n",
        "    def random_subspace(X, n_subspace, random_state=42):\n",
        "        return np.array(np.random.choice(len(X[0]), n_subspace, replace=False)) # 1ый аргумент из какого мн-ва берутся числа, 2ой аргумент - сколько чисел берется\n",
        "    @staticmethod\n",
        "    def get_subsample(X, y, idx_subspace, idx_obj):\n",
        "        x_sampled=X[np.ix_(idx_obj, idx_subspace)] # ix_ - берет пересечение индексов\n",
        "        y_sampled=y[np.array(idx_obj)]\n",
        "        return np.array(x_sampled), np.array(y_sampled)\n",
        "\n",
        "class random_forest(object):\n",
        "    def init(self, n_estimators: int, max_depth: int, subspaces_dim: int, random_state: int):\n",
        "        self.n_estimators = n_estimators # число деревьев\n",
        "        self.max_depth = max_depth\n",
        "        self.subspaces_dim = subspaces_dim # число признаков, которые будем использовать\n",
        "        self.random_state = random_state\n",
        "        self.algs = []\n",
        "        self.cols = [] # массив массивов - то есть список номеров признаков для каждого дерева\n",
        "    def fit(self, X, y):\n",
        "        for i in range(self.n_estimators):\n",
        "            s = sample(X, self.subspaces_dim)\n",
        "            X_sampled, y_sampled = s.get_subsample(X, y, s.idx_subspace, s.bootstrap_sample(X)) # idx_subspace-число столбцов в выборке, bootstrap_sample-число строк в выборке\n",
        "            self.cols.append(s.idx_subspace)\n",
        "            clf = DecisionTreeClassifier(max_depth=self.max_depth, random_state=self.random_state)\n",
        "            clf.fit(X_sampled, y_sampled)\n",
        "            self.algs.append(clf)\n",
        "\n",
        "        self.algs=np.array(self.algs)\n",
        "        self.cols=np.array(self.cols)\n",
        "        pass\n",
        "    def predict(self, X):\n",
        "        n = np.shape(X)[0]\n",
        "        y = []\n",
        "        for i in range(n): # идем по каждому объекту\n",
        "            lst = [] # на каждый объект пустой список ответов\n",
        "            count = [0] * 3\n",
        "            for clf_num in range(self.n_estimators): # идем по деревьям\n",
        "                tmp_X = [] # обнуляем для кажого дерева свою подвыборку\n",
        "                for j in range(len(self.cols[clf_num])): # составляем выборку tmp_X cols[clf_num]\n",
        "                      tmp_X.append(X[i][self.cols[clf_num][j]]) # cols[clf_num]\n",
        "                pred = self.algs[clf_num].predict(np.array(tmp_X).reshape(1,-1))\n",
        "                lst.append(pred) # обучаем деревом self.algs[clf_num] на подвыборке tmp_X\n",
        "            lst = np.array(lst).reshape(1,-1)\n",
        "\n",
        "            # переделываем из массива [[1,2,3]] в массив [1,2,3]\n",
        "            x1 = len(lst[0])\n",
        "            y1 = len(lst)\n",
        "            lst_new = []\n",
        "            for q in range(y1):\n",
        "                for w in lst[q]:\n",
        "                    lst_new.append(w)\n",
        "            lst = lst_new\n",
        "\n",
        "            for num in range(len(lst)): # идем по списку lst, то есть по ответам для каждого объекта i\n",
        "                count[lst[num]] += 1 # заполняем массив count\n",
        "            y.append(np.argmax(count)) # кладем в y нужный класс по методу простого голосования\n",
        "        return np.array(y)\n",
        "\n",
        "\n",
        "N_ESTIMATORS = 7\n",
        "MAX_DEPTH = 11\n",
        "SUBSPACE_DIM = 2"
      ],
      "metadata": {
        "id": "Sj-4iPdZt-EC"
      },
      "execution_count": 1,
      "outputs": []
    }
  ]
}