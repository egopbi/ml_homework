{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 3.2 Градиентный спуск\n",
        "\n",
        "В этом задании нам предстоит реализовать классический алгоритм градиентного спуска для обучения модели логистической регрессии.\n",
        "\n",
        "Алгоритм выполнения этого задания следующий:\n",
        "\n",
        "* На основе посчитанных в первом задании частных производных, напишем функцию подсчета градиента бинарной кросс-энтропии по параметрам модели\n",
        "\n",
        "* Напишем функцию обновления весов по посчитанным градиентам\n",
        "\n",
        "* Напишем функцию тренировки модели\n",
        "\n",
        "Замечание:\n",
        "Тренировка модели проводится в несколько циклов, в рамках каждого из которых мы обновим веса модели, основываясь на предсказании для **каждого** объекта из датасета. Такие циклы называются *эпохами*. То есть одна эпоха - это набор обновлений весов, реализованный согласно посчитанным для каждого объекта из датасета ошибкам модели.\n",
        "\n",
        "Вам необходимо реализовать обучение модели в несколько эпох. Их количество задается параметром функции. В рамках каждой эпохи необходимо пройти циклом по всем объектам обучающей выборки и обновить веса модели."
      ],
      "metadata": {
        "id": "zVKa9zcWdm-p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Шаблон кода для заполнения:"
      ],
      "metadata": {
        "id": "zrTqdyBid_G8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Функция подсчета градиента\n",
        "def gradient(y_true: int, y_pred: float, x: np.array) -> np.array:\n",
        "  x0 = np.array([1])\n",
        "  q = np.concatenate((x, x0))\n",
        "  row, column = np.shape ([q])\n",
        "  grad = np.zeros(column)\n",
        "  for i in range (column):\n",
        "    grad[i] = q[i]*((1-y_true)*y_pred - y_true*(1-y_pred))\n",
        "\n",
        "\n",
        "\n",
        "  \"\"\"\n",
        "    y_true - истинное значение ответа для объекта x\n",
        "    y_pred - значение степени принадлежности объекта x классу 1, предсказанное нашей моделью\n",
        "    x - вектор признакового описания данного объекта\n",
        "\n",
        "    На выходе ожидается получить вектор частных производных H по параметрам модели, предсказавшей значение y_pred\n",
        "    Обратите внимание, что размерность этого градиента должна получиться на единицу больше размерности x засчет своободного коэффициента a0\n",
        "  \"\"\"\n",
        "\n",
        "  pass\n",
        "  return grad\n",
        "\n",
        "\n",
        "# Функция обновления весов\n",
        "def update(alpha: np.array, gradient: np.array, lr: float):\n",
        "  row, column = np.shape ([alpha])\n",
        "  alpha_new = np.zeros (column)\n",
        "  for i in range(column):\n",
        "    alpha_new[i] = alpha[i] - lr * gradient[i]\n",
        "\n",
        "\n",
        "  \"\"\"\n",
        "  alpha: текущее приближения вектора параметров модели\n",
        "  gradient: посчитанный градиент по параметрам модели\n",
        "  lr: learning rate, множитель перед градиентом в формуле обновления параметров\n",
        "  \"\"\"\n",
        "  return alpha_new\n",
        "\n",
        "#функция тренировки модели\n",
        "def train(alpha0: np.array, x_train: np.array, y_train: np.array, lr: float, num_epoch: int):\n",
        "  \"\"\"\n",
        "  alpha0 - начальное приближение параметров модели\n",
        "  x_train - матрица объект-признак обучающей выборки\n",
        "  y_train - верные ответы для обучающей выборки\n",
        "  lr - learning rate, множитель перед градиентом в формуле обновления параметров\n",
        "  num_epoch - количество эпох обучения, то есть полных 'проходов' через весь датасет\n",
        "  \"\"\"\n",
        "  row, column = np.shape(x_train)\n",
        "  w = np.ones((row, 1))\n",
        "  e = np.concatenate((x_train, w), axis=1) #тренировочные точки вместе с единицей на конце (чтобы был размер нужный)\n",
        "  alpha = alpha0.copy()\n",
        "  for epo in range(num_epoch):\n",
        "    for i,x in enumerate(x_train):\n",
        "      #TODO: write your code here\n",
        "      y1 = np.dot(e[i], alpha)\n",
        "      y = 1/(1 + np.exp(-y1))\n",
        "      grad = gradient (y_train[i], y, x_train[i])\n",
        "      alpha = update (alpha, grad, lr)\n",
        "      pass\n",
        "  return alpha"
      ],
      "metadata": {
        "id": "CCM4EIh_d8-n"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#масштабирование координат\n",
        "def scale(X:np.array):\n",
        "    x_mean = X.mean(axis=0)\n",
        "    x_std  = X.std(axis=0)\n",
        "    X_scaled = (X - x_mean)/x_std\n",
        "    return X_scaled\n",
        "class LogisticRegression(object):\n",
        "  def __init__(self):\n",
        "    self.alpha = None\n",
        "    pass\n",
        "  def fit(self, x_train, y_train, lr, num_epoch):\n",
        "    self.x_train = scale(x_train)\n",
        "    self.y_train = y_train\n",
        "    self.lr = lr\n",
        "    self.num_epoch = num_epoch\n",
        "\n",
        "    row, column = np.shape(x_train)\n",
        "    w = np.ones((row, 1))\n",
        "    e = np.concatenate((self.x_train, w), axis=1) #тренировочные точки вместе с единицей на конце (чтобы был размер нужный)\n",
        "    alpha = np.ones(self.x_train.shape[1]+1)\n",
        "    #alpha = train(self.alpha, self.x_train, self.y_train, self.lr, self.num_epoch)\n",
        "    for epo in range(num_epoch):\n",
        "      for i,x in enumerate(x_train):\n",
        "        y1 = np.dot(e[i], alpha)\n",
        "        y = 1/(1 + np.exp(-y1))\n",
        "        grad = gradient (self.y_train[i], y, self.x_train[i])\n",
        "        self.alpha = update (alpha, grad, self.lr)\n",
        "        pass\n",
        "    return self.alpha\n",
        "\n",
        "  def predict(self, X):\n",
        "    self.X = scale(X)\n",
        "    row, column = np.shape(self.X)\n",
        "    ww = np.ones((row, 1))\n",
        "    ee = np.concatenate((self.X, ww), axis=1)\n",
        "    row, column = np.shape(self.X)\n",
        "    preds = np.zeros (row+1).transpose()\n",
        "    for i in range (row):\n",
        "      preds[i] = 1/(1 + np.exp(-np.dot(ee[i], self.alpha)))\n",
        "    return preds"
      ],
      "metadata": {
        "id": "F6GjHgCEmhdP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Ошибка в том, что скалярное произведение очень большое по модулю. Нужно отнормировать и через пайплайн\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "X,y = load_wine(return_X_y=True)\n",
        "X_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
        "LOL = LogisticRegression()\n",
        "LOL.fit(X_train, y_train, 0.05, 8)\n",
        "WWE = LOL.predict(x_test)\n",
        "print(WWE)"
      ],
      "metadata": {
        "id": "wfIg-sn0xcKp",
        "outputId": "093346ee-f2c9-46fa-e910-dd42a1757017",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3.09844829e-07 7.62051195e-03 6.97138924e-01 2.21481710e-01\n",
            " 9.99985037e-01 1.36042101e-01 9.35655778e-01 5.59684528e-02\n",
            " 6.33432840e-01 9.97477339e-01 9.71973393e-01 9.98872386e-01\n",
            " 1.89362144e-01 9.93481703e-01 7.55863033e-01 1.84327939e-01\n",
            " 8.33971433e-01 9.97791576e-01 2.32546528e-01 9.99979038e-01\n",
            " 9.96146275e-01 9.65127813e-01 2.01621581e-03 9.99916265e-01\n",
            " 8.64615861e-01 1.19304590e-01 9.99201544e-01 5.56861593e-02\n",
            " 8.65989384e-02 9.99779891e-01 3.16283519e-01 9.89986715e-01\n",
            " 7.97692406e-02 2.11536801e-02 2.59822342e-01 7.31201159e-03\n",
            " 3.71580028e-01 3.30720976e-02 1.54607624e-01 9.73356458e-01\n",
            " 9.99434914e-01 7.18422455e-01 9.97572523e-01 2.58922039e-02\n",
            " 2.16513153e-03 0.00000000e+00]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Замечание:\n",
        "\n",
        "В случае, если у Вас возникли сложности с выполнением первого задания и, как следствие, у Вас не выходит сделать это, мы рекомендуем подробно ознакомиться с главой **Производные $\\frac{\\partial H}{\\partial \\omega_i}$** нашей [лекции](https://colab.research.google.com/drive/1xjX_YnXcRr8HSiYLByMHxEIAADqs7QES?usp=sharing)"
      ],
      "metadata": {
        "id": "zDcPxeLueFIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x1 = np.array([[10, 5], [0, 4]])\n",
        "x2 = np.ones((2,1))\n",
        "row, column = np.shape(x1)\n",
        "print(x1)\n",
        "w = np.ones((row,1))\n",
        "print(w)\n",
        "r = np.concatenate((x1, w), axis =1)\n",
        "print(r)"
      ],
      "metadata": {
        "id": "ivdSMBwOeb54",
        "outputId": "c0bab45f-6800-40d6-b29a-17ab8cb2d1ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[10  5]\n",
            " [ 0  4]]\n",
            "[[1.]\n",
            " [1.]]\n",
            "[[10.  5.  1.]\n",
            " [ 0.  4.  1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c = np.array([4, 9])\n",
        "v = np.array([3, 2])\n",
        "t = np.dot(c, v)\n",
        "print(t)"
      ],
      "metadata": {
        "id": "_dyc8MUUnGht",
        "outputId": "5aba8909-fd6c-48b4-8700-c162d8aed1df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30\n"
          ]
        }
      ]
    }
  ]
}